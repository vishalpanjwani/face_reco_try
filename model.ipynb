{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2s\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "os.chdir(r'C:\\Users\\visha\\Documents\\try')\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nm', 'sk', 'vk']\n",
      "C:\\Users\\visha\\Documents\\try\\face_trim\\nm\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "C:\\Users\\visha\\Documents\\try\\face_trim\\sk\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "C:\\Users\\visha\\Documents\\try\\face_trim\\vk\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "i:152\n",
      "(152, 96, 96, 3)\n",
      "123.537669042\n",
      "87.2116635912\n",
      "123.061700475\n",
      "86.1353357256\n",
      "122.114149306\n",
      "86.0280675869\n",
      "(152, 96, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "# pre-processing images\n",
    "\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "DIR=r'C:\\Users\\visha\\Documents\\try\\face_trim'\n",
    "l=os.listdir(DIR)\n",
    "i=0\n",
    "gg=[]\n",
    "images=[]\n",
    "print(l)\n",
    "for img in l:\n",
    "   s=os.path.join(DIR,img)\n",
    "   os.chdir(s)\n",
    "   cwd=os.getcwd()\n",
    "   print(cwd)\n",
    "   k=os.listdir(s)\n",
    "   for j in k:\n",
    "       w=os.path.join(s,j)\n",
    "       images.append(cv2.imread(w))\n",
    "       try:\n",
    "           images[i]=cv2.resize(images[i],(96,96))\n",
    "           i+=1\n",
    "       except:\n",
    "           print('failed resizing image %s'%(w))\n",
    "           images=images[:-1]\n",
    "        \n",
    "       #plt.imshow(images[i])\n",
    "       #plt.show()\n",
    "       print(i)\n",
    "       y=np.array(images[i-1])\n",
    "       if(y.shape!=(96,96,3)):\n",
    "           print(w+\" \"+str(y.shape))\n",
    "           images=images[:-1]\n",
    "           gg.append(w)\n",
    "           i-=1\n",
    "images=np.asarray(images)\n",
    "images=images.astype(float)\n",
    "print(\"i:\"+str(i))\n",
    "print(images.shape)\n",
    "for x in range(3):\n",
    "    print(np.mean(images[:,:,x]))\n",
    "    print(np.std(images[:,:,x]))\n",
    "for x in range(3):\n",
    "   images[:,:,x]=np.subtract(images[:,:,x],np.mean(images[:,:,x]))\n",
    "   images[:,:,x]=np.divide(images[:,:,x],np.std(images[:,:,x]))\n",
    "\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.transpose(images,(0,3,1,2))\n",
    "#anchor=images[0:32,:,:,:]\n",
    "#positive=images[32:64,:,:,:]\n",
    "#negative=images[64:80,:,:,:]\n",
    "#negative=np.append(negative,images[140:156,:,:,:],axis=0)\n",
    "#anchor=np.append(anchor,images[64:102,:,:,:],axis=0)\n",
    "#positive=np.append(positive,images[102:140,:,:,:],axis=0)\n",
    "#negative=np.append(negative,images[0:19,:,:,:],axis=0)\n",
    "#negative=np.append(negative,images[140:159,:,:,:],axis=0)\n",
    "#anchor=np.append(anchor,images[140:183,:,:,:],axis=0)\n",
    "#positive=np.append(positive,images[183:226,:,:,:],axis=0)\n",
    "#negative=np.append(negative,images[0:21,:,:,:],axis=0)\n",
    "#negative=np.append(negative,images[32:54,:,:,:],axis=0)\n",
    "#print(anchor.shape)\n",
    "#print(positive.shape)\n",
    "#print(negative.shape)\n",
    "#x=[anchor,positive,negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\visha\\Documents\\try')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))\n",
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \n",
    "    anchor=y_pred[0:22,:]\n",
    "    positive=y_pred[22:44,:]\n",
    "    negative=y_pred[44:55,:]\n",
    "    negative=tf.concat([negative, y_pred[102:113,:]], axis=0)\n",
    "    \n",
    "    anchor=tf.concat([anchor,y_pred[44:73,:]],axis=0)\n",
    "    positive=tf.concat([positive,y_pred[73:102,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[0:14,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[102:117,:]],axis=0 )\n",
    "    \n",
    "    \n",
    "    anchor=tf.concat([anchor,y_pred[102:127,:]],axis=0)\n",
    "    positive=tf.concat([positive,y_pred[127:152,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[0:12,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[44:57,:]],axis=0)\n",
    "    \n",
    "    k=anchor\n",
    "    anchor=tf.concat([anchor,positive],axis=0)\n",
    "    positive=tf.concat([positive,k],axis=0)\n",
    "    \n",
    "    negative=tf.concat([negative,y_pred[55:66,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[113:124,:]],axis=0)\n",
    "    \n",
    "    negative=tf.concat([negative,y_pred[14:28,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[117:132,:]],axis=0)\n",
    "    \n",
    "    negative=tf.concat([negative,y_pred[12:24,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[57:70,:]],axis=0)\n",
    "    \n",
    "    #anchor,positive,negative=y_pred[0],y_pred[1],y_pred[2]\n",
    "    #anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "    basic_loss =tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss,0))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.ones([152,128])\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "152/152 [==============================] - 30s 195ms/step - loss: 49.1876 - acc: 0.0066\n",
      "Epoch 2/100\n",
      "152/152 [==============================] - 36s 240ms/step - loss: 45.6077 - acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "152/152 [==============================] - 38s 252ms/step - loss: 36.7953 - acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "152/152 [==============================] - 37s 246ms/step - loss: 32.4335 - acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "152/152 [==============================] - 38s 253ms/step - loss: 37.7180 - acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "152/152 [==============================] - 38s 253ms/step - loss: 31.0739 - acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 33.3025 - acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "152/152 [==============================] - 40s 262ms/step - loss: 26.6193 - acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 31.9604 - acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 32.2941 - acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "152/152 [==============================] - 40s 261ms/step - loss: 32.1257 - acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 30.5677 - acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "152/152 [==============================] - 39s 257ms/step - loss: 29.1652 - acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "152/152 [==============================] - 39s 257ms/step - loss: 29.7211 - acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "152/152 [==============================] - 40s 260ms/step - loss: 30.3955 - acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "152/152 [==============================] - 39s 253ms/step - loss: 29.9432 - acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "152/152 [==============================] - 39s 259ms/step - loss: 30.3793 - acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 31.2699 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "152/152 [==============================] - 39s 257ms/step - loss: 31.6915 - acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "152/152 [==============================] - 38s 252ms/step - loss: 31.3620 - acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 29.9160 - acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "152/152 [==============================] - 40s 266ms/step - loss: 30.4093 - acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 31.3299 - acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 29.6309 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "152/152 [==============================] - 38s 249ms/step - loss: 30.7334 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 29.9057 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "152/152 [==============================] - 38s 252ms/step - loss: 30.1144 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "152/152 [==============================] - 38s 249ms/step - loss: 31.2854 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "152/152 [==============================] - 39s 253ms/step - loss: 29.3222 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "152/152 [==============================] - 38s 248ms/step - loss: 30.5404 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 31.2433 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 30.6005 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "152/152 [==============================] - 38s 250ms/step - loss: 31.8612 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "152/152 [==============================] - 39s 257ms/step - loss: 29.6396 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 30.3518 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 29.7479 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "152/152 [==============================] - 39s 257ms/step - loss: 31.1737 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 31.1064 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "152/152 [==============================] - 39s 257ms/step - loss: 29.6267 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "152/152 [==============================] - 38s 252ms/step - loss: 30.5317 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 30.0168 - acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "152/152 [==============================] - 38s 252ms/step - loss: 30.2450 - acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 29.1656 - acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 29.3721 - acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 30.9895 - acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "152/152 [==============================] - 40s 266ms/step - loss: 31.7095 - acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "152/152 [==============================] - 38s 252ms/step - loss: 30.6348 - acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "152/152 [==============================] - 40s 266ms/step - loss: 29.7697 - acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "152/152 [==============================] - 40s 262ms/step - loss: 28.8771 - acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "152/152 [==============================] - 40s 262ms/step - loss: 30.6959 - acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "152/152 [==============================] - 41s 267ms/step - loss: 28.8115 - acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "152/152 [==============================] - 39s 259ms/step - loss: 31.4976 - acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "152/152 [==============================] - 40s 261ms/step - loss: 30.8825 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "152/152 [==============================] - 39s 257ms/step - loss: 30.3001 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "152/152 [==============================] - 38s 250ms/step - loss: 30.9651 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "152/152 [==============================] - 38s 252ms/step - loss: 30.5004 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 30.9132 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 30.0298 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "152/152 [==============================] - 39s 257ms/step - loss: 29.4479 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 29.9689 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "152/152 [==============================] - 39s 253ms/step - loss: 29.7031 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 30.0783 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "152/152 [==============================] - 38s 253ms/step - loss: 30.5693 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "152/152 [==============================] - 39s 258ms/step - loss: 30.3990 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 30.8422 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 29.7724 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 30.9707 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "152/152 [==============================] - 39s 255ms/step - loss: 30.4526 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "152/152 [==============================] - 39s 258ms/step - loss: 29.5007 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "152/152 [==============================] - 38s 249ms/step - loss: 31.6638 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "152/152 [==============================] - 39s 256ms/step - loss: 31.3287 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "152/152 [==============================] - 41s 272ms/step - loss: 30.4853 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "152/152 [==============================] - 36s 240ms/step - loss: 31.4282 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "152/152 [==============================] - 33s 215ms/step - loss: 29.5715 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "152/152 [==============================] - 27s 178ms/step - loss: 30.2368 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "152/152 [==============================] - 31s 206ms/step - loss: 28.4559 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 31.5174 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "152/152 [==============================] - 37s 246ms/step - loss: 30.2020 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 31.5729 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "152/152 [==============================] - 39s 259ms/step - loss: 31.8352 - acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "152/152 [==============================] - 38s 253ms/step - loss: 29.8474 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "152/152 [==============================] - 40s 262ms/step - loss: 30.6055 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "152/152 [==============================] - 37s 244ms/step - loss: 31.5477 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "152/152 [==============================] - 39s 254ms/step - loss: 31.6354 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "152/152 [==============================] - 38s 249ms/step - loss: 30.9436 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "152/152 [==============================] - 38s 247ms/step - loss: 31.3740 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "152/152 [==============================] - 37s 246ms/step - loss: 29.7472 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "152/152 [==============================] - 38s 249ms/step - loss: 30.9797 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "152/152 [==============================] - 38s 247ms/step - loss: 30.5451 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 32.1713 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "152/152 [==============================] - 38s 248ms/step - loss: 30.5585 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 30.5258 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "152/152 [==============================] - 38s 251ms/step - loss: 30.1710 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "152/152 [==============================] - 41s 272ms/step - loss: 29.5603 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "152/152 [==============================] - 40s 264ms/step - loss: 29.9892 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "152/152 [==============================] - 40s 266ms/step - loss: 29.4600 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "152/152 [==============================] - 39s 258ms/step - loss: 31.1435 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "152/152 [==============================] - 40s 262ms/step - loss: 29.7279 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "152/152 [==============================] - 41s 270ms/step - loss: 29.1770 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "152/152 [==============================] - 40s 264ms/step - loss: 30.7038 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x233e6be0da0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRmodel.fit( x=x, y=y, epochs=100, batch_size=152)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"modi\"] = img_to_encoding(\"images/modi.jpg\", FRmodel)\n",
    "database[\"khan\"] = img_to_encoding(\"images/khan_test.jpg\", FRmodel)\n",
    "#database[\"aamir\"] = img_to_encoding(\"images/aamir_test.jpg\", FRmodel)\n",
    "#database[\"master_blaster\"] = img_to_encoding(\"images/master_blaster_test.jpg\", FRmodel)\n",
    "database[\"kohli\"] = img_to_encoding(\"images/kohli.jpg\", FRmodel)\n",
    "#database[\"bachan\"] = img_to_encoding(\"images/bachan.jpg\", FRmodel)\n",
    "#database[\"rajan\"] = img_to_encoding(\"images/rajan.jpg\", FRmodel)\n",
    "#database[\"papon\"] = img_to_encoding(\"images/papon.jpg\", FRmodel)\n",
    "#database[\"akshay\"] = img_to_encoding(\"images/akshay.jpg\", FRmodel)\n",
    "#database[\"rahul\"] = img_to_encoding(\"images/rahul.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def who_is_it(image_path, database, model):\n",
    "    \n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    min_dist = 100\n",
    "    \n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "        dist =  np.linalg.norm(encoding-db_enc)\n",
    "        print(dist)\n",
    "        if dist < min_dist:\n",
    "            min_dist =  dist\n",
    "            identity = name\n",
    "\n",
    "    \n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0125844\n",
      "0.0163441\n",
      "0.00979004\n",
      "it's kohli, the distance is 0.00979004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0097900368, 'kohli')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_is_it(\"images/kohli_test.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
