{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2s\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "os.chdir(r'C:\\Users\\visha\\Documents\\try')\n",
    "from fr_utils import *\n",
    "from inception_blocks_v2 import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing images\n",
    "\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "DIR=r'C:\\Users\\visha\\Documents\\try\\face_trim'\n",
    "l=os.listdir(DIR)\n",
    "i=0\n",
    "gg=[]\n",
    "images=[]\n",
    "print(l)\n",
    "for img in l:\n",
    "   s=os.path.join(DIR,img)\n",
    "   os.chdir(s)\n",
    "   cwd=os.getcwd()\n",
    "   print(cwd)\n",
    "   k=os.listdir(s)\n",
    "   for j in k:\n",
    "       w=os.path.join(s,j)\n",
    "       images.append(cv2.imread(w))\n",
    "       try:\n",
    "           images[i]=cv2.resize(images[i],(96,96))\n",
    "           i+=1\n",
    "       except:\n",
    "           print('failed resizing image %s'%(w))\n",
    "           images=images[:-1]\n",
    "        \n",
    "       #plt.imshow(images[i])\n",
    "       #plt.show()\n",
    "       print(i)\n",
    "       y=np.array(images[i-1])\n",
    "       if(y.shape!=(96,96,3)):\n",
    "           print(w+\" \"+str(y.shape))\n",
    "           images=images[:-1]\n",
    "           gg.append(w)\n",
    "           i-=1\n",
    "images=np.asarray(images)\n",
    "images=images.astype(float)\n",
    "print(\"i:\"+str(i))\n",
    "print(images.shape)\n",
    "for x in range(3):\n",
    "    print(np.mean(images[:,:,x]))\n",
    "    print(np.std(images[:,:,x]))\n",
    "for x in range(3):\n",
    "   images[:,:,x]=np.subtract(images[:,:,x],np.mean(images[:,:,x]))\n",
    "   images[:,:,x]=np.divide(images[:,:,x],np.std(images[:,:,x]))\n",
    "\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=np.transpose(images,(0,3,1,2))\n",
    "#anchor=images[0:32,:,:,:]\n",
    "#positive=images[32:64,:,:,:]\n",
    "#negative=images[64:80,:,:,:]\n",
    "#negative=np.append(negative,images[140:156,:,:,:],axis=0)\n",
    "#anchor=np.append(anchor,images[64:102,:,:,:],axis=0)\n",
    "#positive=np.append(positive,images[102:140,:,:,:],axis=0)\n",
    "#negative=np.append(negative,images[0:19,:,:,:],axis=0)\n",
    "#negative=np.append(negative,images[140:159,:,:,:],axis=0)\n",
    "#anchor=np.append(anchor,images[140:183,:,:,:],axis=0)\n",
    "#positive=np.append(positive,images[183:226,:,:,:],axis=0)\n",
    "#negative=np.append(negative,images[0:21,:,:,:],axis=0)\n",
    "#negative=np.append(negative,images[32:54,:,:,:],axis=0)\n",
    "#print(anchor.shape)\n",
    "#print(positive.shape)\n",
    "#print(negative.shape)\n",
    "#x=[anchor,positive,negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\visha\\Documents\\try')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))\n",
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \n",
    "    anchor=y_pred[0:22,:]\n",
    "    positive=y_pred[22:44,:]\n",
    "    negative=y_pred[44:55,:]\n",
    "    negative=tf.concat([negative, y_pred[102:113,:]], axis=0)\n",
    "    \n",
    "    anchor=tf.concat([anchor,y_pred[44:73,:]],axis=0)\n",
    "    positive=tf.concat([positive,y_pred[73:102,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[0:14,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[102:117,:]],axis=0 )\n",
    "    \n",
    "    \n",
    "    anchor=tf.concat([anchor,y_pred[102:127,:]],axis=0)\n",
    "    positive=tf.concat([positive,y_pred[127:152,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[0:12,:]],axis=0)\n",
    "    negative=tf.concat([negative,y_pred[44:57,:]],axis=0)\n",
    "    \n",
    "    #anchor,positive,negative=y_pred[0],y_pred[1],y_pred[2]\n",
    "    #anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    ### START CODE HERE ### (≈ 4 lines)\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss =tf.add(tf.subtract(pos_dist,neg_dist),alpha)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss,0))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FRmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-52b25adbee2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m226\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mFRmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtriplet_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'FRmodel' is not defined"
     ]
    }
   ],
   "source": [
    "y=np.ones([226,128])\n",
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "226/226 [==============================] - 47s 210ms/step - loss: 40.5437 - acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "226/226 [==============================] - 41s 181ms/step - loss: 39.3483 - acc: 0.0044\n",
      "Epoch 3/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 39.5531 - acc: 0.0044\n",
      "Epoch 4/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 35.6643 - acc: 0.0044\n",
      "Epoch 5/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 45.4314 - acc: 0.0088\n",
      "Epoch 6/100\n",
      "226/226 [==============================] - 41s 180ms/step - loss: 32.3251 - acc: 0.0088\n",
      "Epoch 7/100\n",
      "226/226 [==============================] - 40s 176ms/step - loss: 31.0645 - acc: 0.0088\n",
      "Epoch 8/100\n",
      "226/226 [==============================] - 42s 188ms/step - loss: 37.4077 - acc: 0.0177\n",
      "Epoch 9/100\n",
      "226/226 [==============================] - 45s 197ms/step - loss: 33.1030 - acc: 0.0088\n",
      "Epoch 10/100\n",
      "226/226 [==============================] - 43s 192ms/step - loss: 29.6932 - acc: 0.0088\n",
      "Epoch 11/100\n",
      "226/226 [==============================] - 40s 179ms/step - loss: 32.8174 - acc: 0.0088\n",
      "Epoch 12/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 28.0242 - acc: 0.0044\n",
      "Epoch 13/100\n",
      "226/226 [==============================] - 41s 181ms/step - loss: 32.0367 - acc: 0.0044\n",
      "Epoch 14/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 21.1923 - acc: 0.0133\n",
      "Epoch 15/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 23.5634 - acc: 0.0133\n",
      "Epoch 16/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 24.1973 - acc: 0.0133\n",
      "Epoch 17/100\n",
      "226/226 [==============================] - 42s 184ms/step - loss: 26.6003 - acc: 0.0088\n",
      "Epoch 18/100\n",
      "226/226 [==============================] - 41s 180ms/step - loss: 20.7858 - acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 24.7435 - acc: 0.0044\n",
      "Epoch 20/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 23.6856 - acc: 0.0044\n",
      "Epoch 21/100\n",
      "226/226 [==============================] - 41s 182ms/step - loss: 24.7220 - acc: 0.0044\n",
      "Epoch 22/100\n",
      "226/226 [==============================] - 42s 185ms/step - loss: 22.6994 - acc: 0.0044\n",
      "Epoch 23/100\n",
      "226/226 [==============================] - 43s 192ms/step - loss: 22.7460 - acc: 0.0044\n",
      "Epoch 24/100\n",
      "226/226 [==============================] - 41s 180ms/step - loss: 23.6976 - acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "226/226 [==============================] - 41s 180ms/step - loss: 22.6221 - acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 25.0262 - acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 21.6911 - acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 22.1409 - acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 22.2045 - acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 22.8776 - acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 21.5282 - acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 21.3268 - acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 22.5012 - acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 21.9985 - acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 21.0616 - acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "226/226 [==============================] - 40s 176ms/step - loss: 21.9896 - acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 23.2004 - acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "226/226 [==============================] - 40s 176ms/step - loss: 22.9459 - acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "226/226 [==============================] - 41s 180ms/step - loss: 22.2155 - acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 22.0456 - acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 22.8967 - acc: 0.0044\n",
      "Epoch 42/100\n",
      "226/226 [==============================] - 40s 176ms/step - loss: 22.9194 - acc: 0.0044\n",
      "Epoch 43/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 22.0440 - acc: 0.0044\n",
      "Epoch 44/100\n",
      "226/226 [==============================] - 40s 176ms/step - loss: 22.7696 - acc: 0.0044\n",
      "Epoch 45/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 24.0363 - acc: 0.0044\n",
      "Epoch 46/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 22.6348 - acc: 0.0044\n",
      "Epoch 47/100\n",
      "226/226 [==============================] - 40s 179ms/step - loss: 21.5765 - acc: 0.0044\n",
      "Epoch 48/100\n",
      "226/226 [==============================] - 40s 177ms/step - loss: 23.6492 - acc: 0.0044\n",
      "Epoch 49/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 23.0058 - acc: 0.0044\n",
      "Epoch 50/100\n",
      "226/226 [==============================] - 40s 176ms/step - loss: 21.1682 - acc: 0.0044\n",
      "Epoch 51/100\n",
      "226/226 [==============================] - 41s 180ms/step - loss: 21.7931 - acc: 0.0044\n",
      "Epoch 52/100\n",
      "226/226 [==============================] - 40s 176ms/step - loss: 22.6235 - acc: 0.0044\n",
      "Epoch 53/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 21.4608 - acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 22.6121 - acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 21.8613 - acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "226/226 [==============================] - 40s 176ms/step - loss: 22.4041 - acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 20.7000 - acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 20.4211 - acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "226/226 [==============================] - 46s 204ms/step - loss: 21.8959 - acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "226/226 [==============================] - 48s 211ms/step - loss: 23.8523 - acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "226/226 [==============================] - 48s 213ms/step - loss: 23.1855 - acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "226/226 [==============================] - 48s 213ms/step - loss: 19.2776 - acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "226/226 [==============================] - 48s 212ms/step - loss: 23.3401 - acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "226/226 [==============================] - 48s 211ms/step - loss: 21.3132 - acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "226/226 [==============================] - 50s 220ms/step - loss: 22.4144 - acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "226/226 [==============================] - 49s 218ms/step - loss: 23.6175 - acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "226/226 [==============================] - 51s 226ms/step - loss: 21.5803 - acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "226/226 [==============================] - 50s 219ms/step - loss: 21.1382 - acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "226/226 [==============================] - 47s 210ms/step - loss: 22.5698 - acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "226/226 [==============================] - 48s 211ms/step - loss: 21.4892 - acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "226/226 [==============================] - 48s 211ms/step - loss: 22.4057 - acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "226/226 [==============================] - 48s 212ms/step - loss: 23.5233 - acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "226/226 [==============================] - 48s 212ms/step - loss: 24.9268 - acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "226/226 [==============================] - 50s 221ms/step - loss: 23.8695 - acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "226/226 [==============================] - 26589s 118s/step - loss: 22.0999 - acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "226/226 [==============================] - 48s 212ms/step - loss: 23.3413 - acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "226/226 [==============================] - 44s 193ms/step - loss: 20.8752 - acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "226/226 [==============================] - 42s 186ms/step - loss: 21.6438 - acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "226/226 [==============================] - 42s 186ms/step - loss: 22.7353 - acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "226/226 [==============================] - 42s 187ms/step - loss: 22.8834 - acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "226/226 [==============================] - 43s 191ms/step - loss: 23.2759 - acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "226/226 [==============================] - 44s 193ms/step - loss: 21.7537 - acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "226/226 [==============================] - 44s 195ms/step - loss: 22.5881 - acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "226/226 [==============================] - 44s 193ms/step - loss: 23.2812 - acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "226/226 [==============================] - 45s 200ms/step - loss: 22.2564 - acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "226/226 [==============================] - 47s 209ms/step - loss: 22.1305 - acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "226/226 [==============================] - 45s 199ms/step - loss: 22.7679 - acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "226/226 [==============================] - 48s 211ms/step - loss: 24.8352 - acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "226/226 [==============================] - 40s 179ms/step - loss: 21.9598 - acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "226/226 [==============================] - 41s 181ms/step - loss: 22.6440 - acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "226/226 [==============================] - 40s 178ms/step - loss: 22.1363 - acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "226/226 [==============================] - 44s 193ms/step - loss: 24.4209 - acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "226/226 [==============================] - 42s 188ms/step - loss: 22.6599 - acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "226/226 [==============================] - 47s 207ms/step - loss: 23.4041 - acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "226/226 [==============================] - 44s 194ms/step - loss: 21.4482 - acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "226/226 [==============================] - 42s 185ms/step - loss: 22.0337 - acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "226/226 [==============================] - 45s 198ms/step - loss: 22.2620 - acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "226/226 [==============================] - 46s 202ms/step - loss: 23.0893 - acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "226/226 [==============================] - 41s 183ms/step - loss: 23.1090 - acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "226/226 [==============================] - 42s 186ms/step - loss: 23.6499 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c245af1518>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FRmodel.fit( x=x, y=y, epochs=100, batch_size=226)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"modi\"] = img_to_encoding(\"images/modi.jpg\", FRmodel)\n",
    "database[\"khan\"] = img_to_encoding(\"images/khan.jpg\", FRmodel)\n",
    "#database[\"aamir\"] = img_to_encoding(\"images/aamir.jpg\", FRmodel)\n",
    "#database[\"master_blaster\"] = img_to_encoding(\"images/master_blaster.jpg\", FRmodel)\n",
    "#database[\"kohli\"] = img_to_encoding(\"images/kohli.jpg\", FRmodel)\n",
    "#database[\"bachan\"] = img_to_encoding(\"images/bachan.jpg\", FRmodel)\n",
    "#database[\"rajan\"] = img_to_encoding(\"images/rajan.jpg\", FRmodel)\n",
    "#database[\"papon\"] = img_to_encoding(\"images/papon.jpg\", FRmodel)\n",
    "#database[\"akshay\"] = img_to_encoding(\"images/akshay.jpg\", FRmodel)\n",
    "#database[\"rahul\"] = img_to_encoding(\"images/rahul.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def who_is_it(image_path, database, model):\n",
    "    \"\"\"\n",
    "    Implements face recognition for the happy house by finding who is the person on the image_path image.\n",
    "    \n",
    "    Arguments:\n",
    "    image_path -- path to an image\n",
    "    database -- database containing image encodings along with the name of the person on the image\n",
    "    model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "    min_dist -- the minimum distance between image_path encoding and the encodings from the database\n",
    "    identity -- string, the name prediction for the person on image_path\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    \n",
    "    ## Step 1: Compute the target \"encoding\" for the image. Use img_to_encoding() see example above. ## (≈ 1 line)\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    \n",
    "    ## Step 2: Find the closest encoding ##\n",
    "    \n",
    "    # Initialize \"min_dist\" to a large value, say 100 (≈1 line)\n",
    "    min_dist = 100\n",
    "    \n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "        # Compute L2 distance between the target \"encoding\" and the current \"emb\" from the database. (≈ 1 line)\n",
    "        dist =  np.linalg.norm(encoding-db_enc)\n",
    "\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)\n",
    "        if dist < min_dist:\n",
    "            min_dist =  dist\n",
    "            identity = name\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's khan, the distance is 0.00845334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0084533403, 'khan')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_is_it(\"images/khan_test.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
